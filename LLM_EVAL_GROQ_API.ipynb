{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff35ed8-79ba-429c-b9f0-391c4d997ba8",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9395daeb-1c4e-4402-b67d-b2f50cfb6580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-groq in d:\\conda\\lib\\site-packages (0.2.4)\n",
      "Requirement already satisfied: langchain_community in d:\\conda\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain-core in d:\\conda\\lib\\site-packages (0.3.40)\n",
      "Requirement already satisfied: pydantic in d:\\conda\\lib\\site-packages (2.10.6)\n",
      "Requirement already satisfied: bs4 in d:\\conda\\lib\\site-packages (0.0.2)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in d:\\conda\\lib\\site-packages (from langchain-groq) (0.18.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.19 in d:\\conda\\lib\\site-packages (from langchain_community) (0.3.19)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\conda\\lib\\site-packages (from langchain_community) (1.4.44)\n",
      "Requirement already satisfied: requests<3,>=2 in d:\\conda\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in d:\\conda\\lib\\site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\conda\\lib\\site-packages (from langchain_community) (3.11.11)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in d:\\conda\\lib\\site-packages (from langchain_community) (8.2.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\conda\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in d:\\conda\\lib\\site-packages (from langchain_community) (2.8.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in d:\\conda\\lib\\site-packages (from langchain_community) (0.3.10)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in d:\\conda\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<2,>=1.26.4 in d:\\conda\\lib\\site-packages (from langchain_community) (1.26.4)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\conda\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in d:\\conda\\lib\\site-packages (from langchain-core) (23.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in d:\\conda\\lib\\site-packages (from langchain-core) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\conda\\lib\\site-packages (from pydantic) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in d:\\conda\\lib\\site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: beautifulsoup4 in d:\\conda\\lib\\site-packages (from bs4) (4.12.3)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\conda\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\conda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\conda\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\conda\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (4.2.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\conda\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\conda\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (0.28.1)\n",
      "Requirement already satisfied: sniffio in d:\\conda\\lib\\site-packages (from groq<1,>=0.4.1->langchain-groq) (1.3.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in d:\\conda\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core) (2.1)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in d:\\conda\\lib\\site-packages (from langchain<1.0.0,>=0.3.19->langchain_community) (0.3.6)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in d:\\conda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.15)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in d:\\conda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in d:\\conda\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in d:\\conda\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (0.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\conda\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\conda\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\conda\\lib\\site-packages (from requests<3,>=2->langchain_community) (1.26.20)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\conda\\lib\\site-packages (from requests<3,>=2->langchain_community) (2024.6.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in d:\\conda\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (2.0.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in d:\\conda\\lib\\site-packages (from beautifulsoup4->bs4) (2.5)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\conda\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain-groq) (1.1.2)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\conda\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in d:\\conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain-groq) (0.14.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\conda\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install the required packages\n",
    "!pip install langchain-groq langchain_community langchain-core pydantic bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f44769c-4da2-44a7-ac71-375ff77cdb2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "GROQ_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "import os\n",
    "import requests\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f73e29cb-3c21-427e-aaf5-22b03cf980be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "LANGSMITH_API_KEY:  ········\n"
     ]
    }
   ],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf327a54-6f5b-44e7-8134-fb83eda71a91",
   "metadata": {},
   "source": [
    "## LLM SET UP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e5c38a6-954b-472d-be33-099fa3511e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup\n",
    "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
    "\n",
    "# Load and process the LCEL documentation\n",
    "url = \"https://python.langchain.com/docs/concepts/lcel/\"\n",
    "loader = RecursiveUrlLoader(\n",
    "    url=url, max_depth=20, extractor=lambda x: Soup(x, \"html.parser\").text\n",
    ")\n",
    "docs = loader.load()\n",
    "\n",
    "# Sort the list based on the URLs and get the text\n",
    "d_sorted = sorted(docs, key=lambda x: x.metadata[\"source\"])\n",
    "d_reversed = list(reversed(d_sorted))\n",
    "concatenated_content = \"\\n\\n\\n --- \\n\\n\\n\".join(\n",
    "    [doc.page_content for doc in d_reversed]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3d8bfbcd-1ab4-43c2-b9fd-8f60ccb8cfc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: RetryError[<Future at 0x1a16a750d30 state=finished raised AttributeError>]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from pydantic import BaseModel, Field\n",
    "import os\n",
    "\n",
    "# Define the prompt template\n",
    "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"<instructions> You are a coding assistant with expertise in LCEL, LangChain expression language. \\n \n",
    "    Here is the LCEL documentation:  \\n ------- \\n  {context} \\n ------- \\n Answer the user question based on the \\n \n",
    "    above provided documentation. Ensure any code you provide can be executed with all required imports and variables \\n\n",
    "    defined. Structure your answer: 1) a prefix describing the code solution, 2) the imports, 3) the functioning code block. \\n\n",
    "    </instructions> \\n Here is the user question:\"\"\",\n",
    "        ),\n",
    "        (\"placeholder\", \"{messages}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Initialize the Groq client\n",
    "api_key = os.environ.get(\"GROQ_API_KEY\")\n",
    "expt_llm = \"llama-3.1-8b-instant\"\n",
    "llm = ChatGroq(temperature=0, model_name=expt_llm, api_key=api_key)\n",
    "\n",
    "# Data model for the code solution\n",
    "class Code(BaseModel):\n",
    "    \"\"\"Schema for code solutions to questions about LCEL.\"\"\"\n",
    "    prefix: str = Field(description=\"Description of the problem and approach\")\n",
    "    imports: str = Field(description=\"Code block import statements\")\n",
    "    code: str = Field(description=\"Code block not including import statements\")\n",
    "\n",
    "# Add structured output support\n",
    "structured_llm = llm.with_structured_output(Code, include_raw=True)\n",
    "\n",
    "# Function to check for errors in the output\n",
    "def check_groq_output(tool_output):\n",
    "    \"\"\"Check for parse error or failure to call the tool.\"\"\"\n",
    "    # Error with parsing\n",
    "    if tool_output.get(\"parsing_error\"):\n",
    "        print(\"Parsing error!\")\n",
    "        raw_output = str(tool_output[\"raw\"].content)\n",
    "        error = tool_output[\"parsing_error\"]\n",
    "        raise ValueError(\n",
    "            f\"Error parsing your output! Be sure to invoke the tool. Output: {raw_output}. \\n Parse error: {error}\"\n",
    "        )\n",
    "\n",
    "    # Tool was not invoked\n",
    "    elif not tool_output.get(\"parsed\"):\n",
    "        print(\"Failed to invoke tool!\")\n",
    "        raise ValueError(\n",
    "            \"You did not use the provided tool! Be sure to invoke the tool to structure the output.\"\n",
    "        )\n",
    "    \n",
    "    return tool_output\n",
    "\n",
    "# Chain with output check\n",
    "code_chain_groq = code_gen_prompt | structured_llm | check_groq_output\n",
    "\n",
    "# Function to parse the output into the Code schema\n",
    "def parse_output(response: str) -> Code:\n",
    "    \"\"\"Parse the response into the Code schema.\"\"\"\n",
    "    try:\n",
    "        # Attempt to split the response into prefix, imports, and code\n",
    "        if \"Imports:\" in response and \"Code:\" in response:\n",
    "            prefix = response.split(\"Imports:\")[0].strip()\n",
    "            imports = response.split(\"Imports:\")[1].split(\"Code:\")[0].strip()\n",
    "            code = response.split(\"Code:\")[1].strip()\n",
    "        else:\n",
    "            # If the response doesn't contain the expected delimiters, use the entire response as the code\n",
    "            prefix = \"\"\n",
    "            imports = \"No imports provided.\"\n",
    "            code = response.strip()\n",
    "        \n",
    "        return Code(prefix=prefix, imports=imports, code=code)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error parsing response: {e}\")\n",
    "\n",
    "# Optional: With re-try to correct for failure to invoke tool\n",
    "def insert_errors(inputs):\n",
    "    \"\"\"Insert errors for tool parsing in the messages.\"\"\"\n",
    "    error = inputs[\"error\"]\n",
    "    messages = inputs[\"messages\"]\n",
    "    messages += [\n",
    "        HumanMessage(\n",
    "            content=f\"Retry. You are required to fix the parsing errors: {error} \\n\\n You must invoke the provided tool.\"\n",
    "        )\n",
    "    ]\n",
    "    return {\n",
    "        \"messages\": messages,\n",
    "        \"context\": inputs[\"context\"],\n",
    "    }\n",
    "\n",
    "# Fallback chain for retries\n",
    "fallback_chain = insert_errors | code_chain_groq\n",
    "N = 3  # Max re-tries\n",
    "code_gen_chain_with_retry = code_chain_groq.with_fallbacks(\n",
    "    fallbacks=[fallback_chain] * N, exception_key=\"error\"\n",
    ")\n",
    "\n",
    "# Final chain with retry and output parsing\n",
    "code_gen_chain = code_gen_chain_with_retry | parse_output\n",
    "\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "import time\n",
    "\n",
    "# Function to handle rate limits\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def safe_invoke(chain, input_data):\n",
    "    try:\n",
    "        return chain.invoke(input_data)\n",
    "    except groq.RateLimitError as e:\n",
    "        print(f\"Rate limit exceeded. Retrying in {e.retry_after} seconds...\")\n",
    "        time.sleep(e.retry_after)\n",
    "        raise\n",
    "\n",
    "\n",
    "# Example usage\n",
    "question = \"How do I build a RAG chain in LCEL?\"\n",
    "try:\n",
    "    # Invoke the chain\n",
    "    response = safe_invoke(code_gen_chain, {\"context\": concatenated_content, \"messages\": [(\"user\", question)]})\n",
    "    \n",
    "    # Print the solution\n",
    "    print(\"Prefix:\", response.prefix)\n",
    "    print(\"Imports:\", response.imports)\n",
    "    print(\"Code:\", response.code)\n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0dabede-4043-4da1-a314-0283c305a1d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code(prefix='Building a RAG chain in LCEL', imports='from langchain.chains import RetrievalAugmentedGenerator, LLMAgent, WebSearch, Chain', code=\"def build_rag_chain():\\n    # Define the components of the RAG chain\\n    llm = LLMAgent(model_name='text-davinci-003', temperature=0.7)\\n    retriever = WebSearch()\\n    generator = RetrievalAugmentedGenerator(llm, retriever)\\n\\n    # Define the RAG chain\\n    chain = Chain([generator])\\n\\n    return chain\")"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3d7b6b-b9a4-4aa3-841e-26d78b0d6367",
   "metadata": {},
   "source": [
    "## State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "078bd2d0-c9c5-4f4e-a3c8-3f4049fd5791",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph.\n",
    "\n",
    "    Attributes:\n",
    "        error : Binary flag for control flow to indicate whether test error was tripped\n",
    "        messages : With user question, error messages, reasoning\n",
    "        generation : Code solution\n",
    "        iterations : Number of tries\n",
    "    \"\"\"\n",
    "\n",
    "    error: str\n",
    "    messages: List\n",
    "    generation: str\n",
    "    iterations: int"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09315a7c-c8f8-4c60-9e2f-d4f71a6c63f0",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2c4afd6-065b-417b-aab9-468b2ed82026",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Parameter\n",
    "\n",
    "# Max tries\n",
    "max_iterations = 3\n",
    "# Reflect\n",
    "# flag = 'reflect'\n",
    "flag = \"do not reflect\"\n",
    "\n",
    "### Nodes\n",
    "\n",
    "\n",
    "def generate(state: GraphState):\n",
    "    \"\"\"\n",
    "    Generate a code solution\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    error = state[\"error\"]\n",
    "\n",
    "    # We have been routed back to generation with an error\n",
    "    if error == \"yes\":\n",
    "        messages += [\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Now, try again. Invoke the code tool to structure the output with a prefix, imports, and code block:\",\n",
    "            )\n",
    "        ]\n",
    "\n",
    "    # Solution\n",
    "    code_solution = code_gen_chain.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [\n",
    "        (\n",
    "            \"assistant\",\n",
    "            f\"{code_solution.prefix} \\n Imports: {code_solution.imports} \\n Code: {code_solution.code}\",\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Increment\n",
    "    iterations = iterations + 1\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "def code_check(state: GraphState):\n",
    "    \"\"\"\n",
    "    Check code\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, error\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---CHECKING CODE---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    # Get solution components\n",
    "    imports = code_solution.imports\n",
    "    code = code_solution.code\n",
    "\n",
    "    # Check imports\n",
    "    try:\n",
    "        exec(imports)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE IMPORT CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the import test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # Check execution\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "    except Exception as e:\n",
    "        print(\"---CODE BLOCK CHECK: FAILED---\")\n",
    "        error_message = [(\"user\", f\"Your solution failed the code execution test: {e}\")]\n",
    "        messages += error_message\n",
    "        return {\n",
    "            \"generation\": code_solution,\n",
    "            \"messages\": messages,\n",
    "            \"iterations\": iterations,\n",
    "            \"error\": \"yes\",\n",
    "        }\n",
    "\n",
    "    # No errors\n",
    "    print(\"---NO CODE TEST FAILURES---\")\n",
    "    return {\n",
    "        \"generation\": code_solution,\n",
    "        \"messages\": messages,\n",
    "        \"iterations\": iterations,\n",
    "        \"error\": \"no\",\n",
    "    }\n",
    "\n",
    "\n",
    "def reflect(state: GraphState):\n",
    "    \"\"\"\n",
    "    Reflect on errors\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        state (dict): New key added to state, generation\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"---GENERATING CODE SOLUTION---\")\n",
    "\n",
    "    # State\n",
    "    messages = state[\"messages\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "    code_solution = state[\"generation\"]\n",
    "\n",
    "    # Prompt reflection\n",
    "\n",
    "    # Add reflection\n",
    "    reflections = code_gen_chain.invoke(\n",
    "        {\"context\": concatenated_content, \"messages\": messages}\n",
    "    )\n",
    "    messages += [(\"assistant\", f\"Here are reflections on the error: {reflections}\")]\n",
    "    return {\"generation\": code_solution, \"messages\": messages, \"iterations\": iterations}\n",
    "\n",
    "\n",
    "### Edges\n",
    "\n",
    "\n",
    "def decide_to_finish(state: GraphState):\n",
    "    \"\"\"\n",
    "    Determines whether to finish.\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "\n",
    "    Returns:\n",
    "        str: Next node to call\n",
    "    \"\"\"\n",
    "    error = state[\"error\"]\n",
    "    iterations = state[\"iterations\"]\n",
    "\n",
    "    if error == \"no\" or iterations == max_iterations:\n",
    "        print(\"---DECISION: FINISH---\")\n",
    "        return \"end\"\n",
    "    else:\n",
    "        print(\"---DECISION: RE-TRY SOLUTION---\")\n",
    "        if flag == \"reflect\":\n",
    "            return \"reflect\"\n",
    "        else:\n",
    "            return \"generate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d221a2d6-2b96-4b85-8564-d9bd3227772e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "# Define the nodes\n",
    "workflow.add_node(\"generate\", generate)  # generation solution\n",
    "workflow.add_node(\"check_code\", code_check)  # check code\n",
    "workflow.add_node(\"reflect\", reflect)  # reflect\n",
    "\n",
    "# Build graph\n",
    "workflow.add_edge(START, \"generate\")\n",
    "workflow.add_edge(\"generate\", \"check_code\")\n",
    "workflow.add_conditional_edges(\n",
    "    \"check_code\",\n",
    "    decide_to_finish,\n",
    "    {\n",
    "        \"end\": END,\n",
    "        \"reflect\": \"reflect\",\n",
    "        \"generate\": \"generate\",\n",
    "    },\n",
    ")\n",
    "workflow.add_edge(\"reflect\", \"generate\")\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77371dd1-2625-4f90-9292-035789573af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "---GENERATING CODE SOLUTION---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<string>:9: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "---DECISION: RE-TRY SOLUTION---\n",
      "---GENERATING CODE SOLUTION---\n",
      "---CHECKING CODE---\n",
      "---CODE BLOCK CHECK: FAILED---\n",
      "---DECISION: FINISH---\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I directly pass a string to a runnable and use it to construct the input needed for my prompt?\"\n",
    "solution = app.invoke({\"messages\": [(\"user\", question)], \"iterations\": 0, \"error\": \"\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b857a048-29ff-4cc6-9416-83ff4b7f983f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Code(prefix='langchain_core.runnables', imports='from langchain.chains import LLMChain', code='def construct_input(input_string):\\n    prompt_template = \"Given the string \" + input_string + \", the answer is \" + input_string\\n    return LLMChain(llm_name=\"text-davinci-003\", prompt=prompt_template)\\n\\n# Invoke the runnable with a string input\\nresult = construct_input(\"Hello, World!\").invoke()\\n')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solution[\"generation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2ffca6ce-6251-494b-b4d7-3b2228e3df62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langsmith\n",
    "\n",
    "client = langsmith.Client(api_key = os.getenv(\"LANGSMITH_API_KEY\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2027931f-8887-42b1-83d2-f93d01b7ba4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    public_dataset = (\n",
    "        \"https://smith.langchain.com/public/326674a6-62bd-462d-88ae-eea49d503f9d/d\"\n",
    "    )\n",
    "    client.clone_public_dataset(public_dataset)\n",
    "except Exception as e:\n",
    "    print(\"Error cloning dataset:\", str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ed6e523-4e66-4662-b67b-86734a48c0a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='lcel-teacher-eval' description='Eval set for LCEL teacher' data_type=<DataType.kv: 'kv'> id=UUID('5451bb2d-5a52-41a7-aa53-5b12ea1d7f02') created_at=datetime.datetime(2025, 3, 2, 16, 37, 57, 273231, tzinfo=datetime.timezone.utc) modified_at=datetime.datetime(2025, 3, 2, 16, 37, 57, 273231, tzinfo=datetime.timezone.utc) example_count=20 session_count=5 last_session_start_time=datetime.datetime(2025, 3, 2, 17, 56, 31, 926449) inputs_schema={'type': 'object', 'title': 'dataset_input_schema', 'required': ['question'], 'properties': {'question': {'type': 'string'}}} outputs_schema={'type': 'object', 'title': 'dataset_output_schema', 'required': ['answer'], 'properties': {'answer': {'type': 'string'}}} transformations=None\n"
     ]
    }
   ],
   "source": [
    "datasets = client.list_datasets()\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08b6ae95-b259-4e66-849e-8d61f12838e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "\n",
    "def check_import(run: Run, example: Example) -> dict:\n",
    "    imports = run.outputs.get(\"imports\")\n",
    "    try:\n",
    "        exec(imports)\n",
    "        return {\"key\": \"import_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"import_check\", \"score\": 0}\n",
    "\n",
    "\n",
    "def check_execution(run: Run, example: Example) -> dict:\n",
    "    imports = run.outputs.get(\"imports\")\n",
    "    code = run.outputs.get(\"code\")\n",
    "    try:\n",
    "        exec(imports + \"\\n\" + code)\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 1}\n",
    "    except Exception:\n",
    "        return {\"key\": \"code_execution_check\", \"score\": 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc5e5ef0-7f6f-425d-a225-e04eab109e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_base_case(example: dict):\n",
    "    \"\"\"Context stuffing\"\"\"\n",
    "    solution = safe_invoke(code_gen_chain, \n",
    "        {\"context\": concatenated_content, \"messages\": [(\"user\", example[\"question\"])]}\n",
    "    )\n",
    "    return {\"imports\": solution.imports, \"code\": solution.code}\n",
    "\n",
    "\n",
    "def predict_langgraph(example: dict):\n",
    "    \"\"\"LangGraph\"\"\"\n",
    "    graph = safe_invoke(app,\n",
    "        {\"messages\": [(\"user\", example[\"question\"])], \"iterations\": 0, \"error\": \"\"}\n",
    "    )\n",
    "    solution = graph[\"generation\"]\n",
    "    return {\"imports\": solution.imports, \"code\": solution.code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bddbf324-45cf-43bc-9efc-4799cd1e6a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith.evaluation import evaluate\n",
    "\n",
    "# Evaluator\n",
    "code_evalulator = [check_import, check_execution]\n",
    "\n",
    "# Dataset\n",
    "dataset_name = \"lcel-teacher-eval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9df43787-53a1-477e-a6fa-e10ba22568c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-without-langgraph-llama-3.1-8b-instant-35ed37fb' at:\n",
      "https://smith.langchain.com/o/2dbf5add-f9e9-4edb-b995-076e3f219725/datasets/5451bb2d-5a52-41a7-aa53-5b12ea1d7f02/compare?selectedSessions=753a04b7-79ee-4311-9020-25284ec2905c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7faa0faa155433baf931c23e967c524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a166a2a790 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in invoke\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in <dictcomp>\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3713, in _invoke_step\n",
      "    return context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5360, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 284, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 860, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 690, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 925, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 480, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 322, in create\n",
      "    return self._post(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 958, in request\n",
      "    return self._request(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1046, in _request\n",
      "    return self._retry_request(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1095, in _retry_request\n",
      "    return self._request(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ' {\"prefix\": \"Process text with a function before passing it to the prompt using LCEL.\", \"imports\": \"from langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain, Source\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\3919508693.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a166a2a790 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16abfea90 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4721, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1922, in _call_with_config\n",
      "    context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4575, in _invoke\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 46, in check_groq_output\n",
      "    raise ValueError(\n",
      "ValueError: Error parsing your output! Be sure to invoke the tool. Output: . \n",
      " Parse error: 1 validation error for Code\n",
      "imports\n",
      "  Field required [type=missing, input_value={'prefix': 'To structure ...tput_model.code_block)\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\3919508693.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16abfea90 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16a201b50 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4721, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1922, in _call_with_config\n",
      "    context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4575, in _invoke\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 46, in check_groq_output\n",
      "    raise ValueError(\n",
      "ValueError: Error parsing your output! Be sure to invoke the tool. Output: . \n",
      " Parse error: 3 validation errors for Code\n",
      "prefix\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "imports\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "code\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\3919508693.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16a201b50 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    }
   ],
   "source": [
    "# Run base case\n",
    "try:\n",
    "    experiment_results_ = client.evaluate(\n",
    "        predict_base_case,\n",
    "        data=dataset_name,\n",
    "        evaluators=code_evalulator,\n",
    "        experiment_prefix=f\"test-without-langgraph-{expt_llm}\",\n",
    "        max_concurrency=2,\n",
    "        metadata={\n",
    "            \"llm\": expt_llm,\n",
    "        },\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"LangSmith setup error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "10c13627-d155-42d3-9b49-60044d7df023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'test-without-langgraph-llama-3.1-8b-instant-870d45a7' at:\n",
      "https://smith.langchain.com/o/2dbf5add-f9e9-4edb-b995-076e3f219725/datasets/5451bb2d-5a52-41a7-aa53-5b12ea1d7f02/compare?selectedSessions=a133b5cd-7463-483d-86f5-fbfe03a8b19c\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eacf8ccf06d4f2d9135e7485a30ac30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16a0c8dc0 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4721, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1922, in _call_with_config\n",
      "    context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4575, in _invoke\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 46, in check_groq_output\n",
      "    raise ValueError(\n",
      "ValueError: Error parsing your output! Be sure to invoke the tool. Output: . \n",
      " Parse error: 1 validation error for Code\n",
      "imports\n",
      "  Field required [type=missing, input_value={'prefix': 'To structure ...tput_model.code_block)\"}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\1191718553.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16a0c8dc0 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16a1be2b0 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in invoke\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in <dictcomp>\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3713, in _invoke_step\n",
      "    return context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5360, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 284, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 860, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 690, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 925, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 480, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 322, in create\n",
      "    return self._post(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 958, in request\n",
      "    return self._request(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.BadRequestError: Error code: 400 - {'error': {'message': \"Failed to call a function. Please adjust your prompt. See 'failed_generation' for more details.\", 'type': 'invalid_request_error', 'code': 'tool_use_failed', 'failed_generation': ' {\"prefix\": \"Process text with a function before passing it to the prompt using LCEL.\", \"imports\": \"from langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain, Source\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Source\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms import BaseLLM\\\\nfrom langchain import Chain\\\\nfrom langchain.llms import BaseLLM\\\\nfrom langchain.chains import LLMChain\\\\nfrom langchain.chains.llms'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\1191718553.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16a1be2b0 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16a298940 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4721, in invoke\n",
      "    return self._call_with_config(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 1922, in _call_with_config\n",
      "    context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 4575, in _invoke\n",
      "    output = call_func_with_variable_args(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\config.py\", line 396, in call_func_with_variable_args\n",
      "    return func(input, **kwargs)  # type: ignore[call-arg]\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 46, in check_groq_output\n",
      "    raise ValueError(\n",
      "ValueError: Error parsing your output! Be sure to invoke the tool. Output: . \n",
      " Parse error: 3 validation errors for Code\n",
      "prefix\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "imports\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "code\n",
      "  Field required [type=missing, input_value={'name': 'Convert LCEL ch...e the str() function.'}}, input_type=dict]\n",
      "    For further information visit https://errors.pydantic.dev/2.10/v/missing\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\1191718553.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16a298940 state=finished raised NameError>]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n",
      "Parsing error!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error running target function: RetryError[<Future at 0x1a16a667c10 state=finished raised NameError>]\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 101, in safe_invoke\n",
      "    return chain.invoke(input_data)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3022, in invoke\n",
      "    input = context.run(step.invoke, input, config, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 199, in invoke\n",
      "    raise first_error\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\fallbacks.py\", line 179, in invoke\n",
      "    output = context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3024, in invoke\n",
      "    input = context.run(step.invoke, input, config)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in invoke\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3729, in <dictcomp>\n",
      "    output = {key: future.result() for key, future in zip(steps, futures)}\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 446, in result\n",
      "    return self.__get_result()\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\_base.py\", line 391, in __get_result\n",
      "    raise self._exception\n",
      "  File \"D:\\Conda\\lib\\concurrent\\futures\\thread.py\", line 58, in run\n",
      "    result = self.fn(*self.args, **self.kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 3713, in _invoke_step\n",
      "    return context.run(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\runnables\\base.py\", line 5360, in invoke\n",
      "    return self.bound.invoke(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 284, in invoke\n",
      "    self.generate_prompt(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 860, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 690, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 925, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langchain_groq\\chat_models.py\", line 480, in _generate\n",
      "    response = self.client.create(messages=message_dicts, **params)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\resources\\chat\\completions.py\", line 322, in create\n",
      "    return self._post(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1266, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 958, in request\n",
      "    return self._request(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\groq\\_base_client.py\", line 1061, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-8b-instant` in organization `org_01jmt1m4nne17bay1a6ky12es7` service tier `on_demand` on : Limit 500000, Used 497218, Requested 4146. Please try again in 3m55.5784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': '', 'code': 'rate_limit_exceeded'}}\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 382, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\4984125.py\", line 102, in safe_invoke\n",
      "    except groq.RateLimitError as e:\n",
      "NameError: name 'groq' is not defined\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1914, in _forward\n",
      "    fn(\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 634, in wrapper\n",
      "    raise e\n",
      "  File \"D:\\Conda\\lib\\site-packages\\langsmith\\run_helpers.py\", line 631, in wrapper\n",
      "    function_result = run_container[\"context\"].run(func, *args, **kwargs)\n",
      "  File \"C:\\Users\\kuany\\AppData\\Local\\Temp\\ipykernel_11564\\1191718553.py\", line 3, in predict_base_case\n",
      "    solution = safe_invoke(code_gen_chain,\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 289, in wrapped_f\n",
      "    return self(f, *args, **kw)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 379, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"D:\\Conda\\lib\\site-packages\\tenacity\\__init__.py\", line 326, in iter\n",
      "    raise retry_exc from fut.exception()\n",
      "tenacity.RetryError: RetryError[<Future at 0x1a16a667c10 state=finished raised NameError>]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    experiment_results_ = client.evaluate(\n",
    "        predict_base_case,\n",
    "        data=dataset,\n",
    "        evaluators=code_evalulator,\n",
    "        experiment_prefix=f\"test-without-langgraph-{expt_llm}\",\n",
    "        max_concurrency=2,\n",
    "        metadata={\"llm\": expt_llm},\n",
    "    )\n",
    "except Exception as e:\n",
    "    print(f\"LangSmith setup error: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c18a6e7-aaf9-48b6-bdae-23c1d154195b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
